{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b161ed6-2219-42ea-8800-eeddd1eaf00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "def timer(func):\n",
    "    \"\"\"Print the runtime of the decorated function\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        start_time = time.perf_counter()    # 1\n",
    "        value = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()      # 2\n",
    "        run_time = end_time - start_time    # 3\n",
    "        print(f\"Finished {func.__name__!r} in {run_time:.4f} secs\")\n",
    "        return value\n",
    "    return wrapper_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "fb2a42d8-4af5-4e09-91e6-c2e2ed1bc07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# The start and end dates of U.S. daylight savings time (DST) matches up with the transition points in the training data.\n",
    "# source: https://en.wikipedia.org/wiki/History_of_time_in_the_United_States\n",
    "DST_START_DTS = [\"3/8/26\", \"3/9/25\", \"3/10/24\", \"3/12/23\", \"3/13/22\", \"3/14/21\", \"3/8/20\", \"3/10/19\", \"3/11/18\", \"3/12/17\",\n",
    "                 \"3/13/16\", \"3/8/15\", \"3/9/14\", \"3/10/13\", \"3/11/12\", \"3/13/11\", \"3/14/10\", \"3/8/09\", \"3/9/08\", \"3/11/07\",\n",
    "                 \"4/2/06\", \"4/3/05\", \"4/4/04\", \"4/6/03\", \"4/7/02\", \"4/1/01\", \"4/2/00\"]\n",
    "\n",
    "DST_END_DTS = [\"11/1/26\", \"11/2/25\", \"11/3/24\", \"11/5/23\", \"11/6/22\", \"11/7/21\", \"11/1/20\", \"11/3/19\", \"11/4/18\", \"11/5/17\",\n",
    "               \"11/6/16\", \"11/1/15\", \"11/2/14\", \"11/3/13\", \"11/4/12\", \"11/6/11\", \"11/7/10\", \"11/1/09\", \"11/2/08\", \"11/4/07\",\n",
    "               \"10/29/06\", \"10/30/05\", \"10/31/04\", \"10/26/03\", \"10/27/02\", \"10/28/01\", \"10/29/00\"]\n",
    "\n",
    "# Create dictionaries with the days of the year when DST ends and starts for the years 2000-2026.\n",
    "dstEndDayOfYearDict = {dt.year:dt.dayofyear for dt in pd.to_datetime(DST_END_DTS)}\n",
    "dstStartDayOfYearDict = {dt.year:dt.dayofyear for dt in pd.to_datetime(DST_START_DTS)}\n",
    "\n",
    "# Outside of dailight savings, the first daily price sample in data.csv is at 15:05:00.\n",
    "FIRST_SEC_OUT_OF_DST = 60 * (15 * 60 + 5)\n",
    "# Within daylight savings, the first daily price sample in data.csv is at 14:05:00.\n",
    "FIRST_SEC_IN_DST = 60 * (14 * 60 + 5)\n",
    "\n",
    "def shiftBackArray(arrayIn, fillFirstValue=np.nan):\n",
    "    \"\"\"\n",
    "    Back-shift a given array.\n",
    "\n",
    "    Args:\n",
    "        arrayIn (array_like): vector to back-shift\n",
    "        fillFirstValue (float): value to put in first entry of returned vector\n",
    "\n",
    "    Returns:\n",
    "        arrayOut (np.array): back-shifted vector\n",
    "\n",
    "    \"\"\"\n",
    "    arrayOut = np.empty_like(arrayIn)\n",
    "    arrayOut[0] = fillFirstValue\n",
    "    arrayOut[1:] = np.where(np.isnan(arrayIn[1:]), np.nan, arrayIn[:-1])\n",
    "    return arrayOut\n",
    "\n",
    "def getData(dataFilename, numLagsDict={'x':25, 'y':25}, rowsPerDay=1410):\n",
    "    \"\"\"\n",
    "    Read and process the price data .csv file at the given path.\n",
    "    Create date and time variables that provide consisitency across the different days\n",
    "        and daylight savings time periods in the data.\n",
    "    Create specified number of lagged price difference variables.\n",
    "\n",
    "    Args:\n",
    "        dataFilename (str): path to data (.csv)\n",
    "        numLagsDict (Dict[str, int]): dictionary specifying number of lagged diffences\n",
    "            to create for (x and y) price variables\n",
    "        rowsPerDay (int): number of rows (samples) per trading day \n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): dataframe with processed data\n",
    "\n",
    "    \"\"\"\n",
    "    # Read in .csv file.\n",
    "    df = pd.read_csv(dataFilename)\n",
    "    \n",
    "    # Create date and time variables.\n",
    "    df['dt'] = np.repeat(np.datetime64('1970-01-01T00:00:00'), len(df)) + df.timestamp.values * np.timedelta64(1, 'ms')\n",
    "    df['dayOfYear'] = df['dt'].dt.dayofyear\n",
    "    df['secondInDay'] = 3600 * df['dt'].dt.hour + 60 * df['dt'].dt.minute + df['dt'].dt.second\n",
    "    # Create a consistent daily time index variable.\n",
    "    df['timeID'] = np.where(\n",
    "            # condition for whether a given row falls outside of Daylight Savings Time (DST)\n",
    "        (df['dayOfYear'] < df['dt'].dt.year.map(dstStartDayOfYearDict)) | (df['dayOfYear'] > df['dt'].dt.year.map(dstEndDayOfYearDict)),\n",
    "        (df['secondInDay'] - FIRST_SEC_OUT_OF_DST) // 10,\n",
    "        (df['secondInDay'] - FIRST_SEC_IN_DST) // 10\n",
    "    )\n",
    "\n",
    "    # Create variable for the number of steps forward to the yprice row that the returns values are based on. This is 60 when\n",
    "    # price data is available ten minutes forward; otherwise it's the number of steps to the final row of the current day.\n",
    "    df['stepsToReturnsPrice'] = np.where(rowsPerDay - 1 - df['timeID'] > 60, 60, rowsPerDay - 1 - df['timeID'])\n",
    "\n",
    "    # Create variables for lagged differences in xprice and yprice.\n",
    "    for var, numLags in numLagsDict.items():\n",
    "        # First compute the difference between each row's current price and the previous price (from 10 seconds before).\n",
    "        # If there is no previous price available then set variable to zero.\n",
    "        df[var+'DiffLag0'] = np.where((df['timeID'] > numLags - 1) & (df['stepsToReturnsPrice'] > 0),\n",
    "                               df[var+'price'] - shiftBackArray(df[var+'price'].values, fillFirstValue=0.), 0.)\n",
    "        # Next create the lagged differences variables.\n",
    "        for lag in range(1, numLags):\n",
    "            df[var+'DiffLag'+str(lag)] = np.where((df['timeID'] > numLags-1) & (df['stepsToReturnsPrice'] > lag),\n",
    "                                                  shiftBackArray(df[var+'DiffLag'+str(lag-1)], fillFirstValue=0.), 0.)\n",
    "    return df\n",
    "\n",
    "\n",
    "def estimateForecastWindow(df, startTrainIndex, trainWindowSize, forecastHorizon,\n",
    "             covariates, ridgeModel, trainToPredictOffset=60):\n",
    "    \"\"\"\n",
    "    Fit weighted ridge regression model with specified covariates to the specified\n",
    "        training window rows in df.\n",
    "    Create training weights based on the distance between values in the training rows\n",
    "        and the average values across the training window.\n",
    "    Update the 'prediction' column of df with predictions based on the fitted ridge\n",
    "        model and the covariate values within the specified prediction range.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): data to use for training and to update with predictions\n",
    "        startTrainIndex (int): index at which training window starts\n",
    "        trainWindowSize (int): number of rows to include in training window\n",
    "        forecastHorizon (int): number of forward predictions to make\n",
    "        covariates (List[str]): covariates to include in ridge regression model\n",
    "        ridgeModel (sklearn.linear_model.Ridge): sklearn ridge regession model\n",
    "            to fit and predict from\n",
    "        trainToPredictOffset (int): periods (rows) between the end of the training window \n",
    "            and the first prediction\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    # Set index specifying the training window (along with startTrainIndex).\n",
    "    endTrainIndex = startTrainIndex + trainWindowSize - 1\n",
    "    \n",
    "    # Set indices corresponding to the prediction horizon.\n",
    "    startPredictIndex = endTrainIndex + trainToPredictOffset\n",
    "    endPredictIndex = startPredictIndex + forecastHorizon - 1\n",
    "\n",
    "    # Compute 'center' of values across training window - the mean of the covariates and returns.\n",
    "    trainRowsCenter = df.loc[startTrainIndex:endTrainIndex, covariates+['returns']].mean(axis=0).values\n",
    "    \n",
    "    # Compute 'scale' vector capturing variability across the training window.\n",
    "    # This contains the sample standard deviations for each covariate along with the sample standard deviation of the returns\n",
    "    # column divided by .5 times the number of covariates (putting increased weight on the deviations of the returns values).\n",
    "    # The ratio of total weight put on the deviations of the covariates to the weight put on the returns deviations is 2:1.\n",
    "    trainRowsScale = df.loc[startTrainIndex:endTrainIndex, covariates+['returns']].std(axis=0).values\n",
    "    trainRowsScale[-1] /= (len(covariates) / 2)\n",
    "\n",
    "    # Use the scipy.spatial.distance.cdist function to compute standardized (weighted) euclidean distances\n",
    "    # between the covariates & returns values and the trainRowsCenter for each training row.\n",
    "    distances = cdist(np.expand_dims(trainRowsCenter,0),\n",
    "                      df.loc[startTrainIndex:endTrainIndex, covariates+['returns']].values,\n",
    "                      metric='seuclidean', V=trainRowsScale)[0]\n",
    "\n",
    "    # Compute training weights from these distances using the Gaussian kernel function, phi(x) = exp(-.5 * (x-center)^2 / width)\n",
    "    # with center equal to the average of the distances, and width equal to 3x the number of covariates.\n",
    "    # Note this width is equal to the theoretical variance of the computed distances if the covariates and returns were all\n",
    "    # independent and normally distributed\n",
    "    trainWeights = np.exp(-np.square(distances - np.mean(distances)) / (6 * len(covariates)))\n",
    "\n",
    "    # Estimate model coefficients with weighted ridge regression using the sklearn package.\n",
    "    # Note: the fit is based only on data within the training window\n",
    "    ridgeModel.fit(df.loc[startTrainIndex:endTrainIndex, covariates].values,\n",
    "                   df.loc[startTrainIndex:endTrainIndex, 'returns'].values,\n",
    "                   sample_weight=trainWeights)\n",
    "    \n",
    "    # Use the estimated model to make forward predictions.\n",
    "    # this is an in-place operation, directly updating the 'prediction' column of the input dataframe (df).\n",
    "    df.loc[startPredictIndex:endPredictIndex, 'prediction'] \\\n",
    "        = ridgeModel.predict(df.loc[startPredictIndex:endPredictIndex, covariates].values)\n",
    "\n",
    "def modelEstimate(trainingFilename):\n",
    "    \"\"\"\n",
    "    **All model fitting takes place along with prediction in the modelForecast function.**\n",
    "    This function creates and returns the dictionary 'parameters' containing trainingFilename\n",
    "    along with data parameters and hyperparameters for the model (see descriptions below).\n",
    "\n",
    "    Args:\n",
    "        trainingFilename (str): path to training data. The data will\n",
    "            be in the same format as the supplied `data.csv` file\n",
    "\n",
    "    Returns:\n",
    "        parameters (Dict[str, any]): the parameters needed to pass to modelForecast\n",
    "            \n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "            # specified path to training data\n",
    "        'trainingFilename':trainingFilename,\n",
    "            # number of rows to include in training window and estimate model with\n",
    "            # equal to: rowsPerDay * 25 - trainToPredictOffset + 1\n",
    "            # that is, the training window size is (just short of) 25 days worth of price data\n",
    "        'trainWindowSize':1410 * 25 - 60 + 1,\n",
    "            # number of forward predictions for each training window and estimated model\n",
    "            # equal to: rowsPerDay // 2\n",
    "            # that is, for each rolling window of data, a half-day worth of forecasts are made\n",
    "        'forecastHorizon':1410 // 2,\n",
    "            # hyperparameters specifying how many lagged price differences of the X and Y instruments\n",
    "            # to include in the regression model\n",
    "        'numLagsDict':{'x':25, 'y':22},\n",
    "            # the returns column (variable to predict) is (for the most part) based on prices ten minutes from now,\n",
    "            # so the number of rows between the last training row and first predicted row needs to be (at least) 60\n",
    "            # (60 x ten seconds = 10 min)\n",
    "        'trainToPredictOffset':60,\n",
    "            # hyperparamter controlling l2 regrularization in ridge regression\n",
    "        'alpha':1.3,\n",
    "            # there are 1410 rows per day in data.csv\n",
    "        'rowsPerDay':1410\n",
    "    }\n",
    "    return(parameters)\n",
    "\n",
    "@timer\n",
    "def modelForecast(testFilename, parameters):\n",
    "    \"\"\"\n",
    "    Predict returns using a fitted model.\n",
    "\n",
    "    Args:\n",
    "        testFilename (str): path to test data. The data will be in\n",
    "            the same format as the supplied `data.csv` file\n",
    "        parameters (Dict[str, any]): data parameters and hyperparameters for forecasting, see\n",
    "            descriptions in the modelEstimate function above.\n",
    "            \n",
    "    Returns:\n",
    "        forecast (np.array): vector of predictions.\n",
    "\n",
    "    \"\"\"\n",
    "    # Read in and process training and test data.\n",
    "    trainData = getData(parameters['trainingFilename'],\n",
    "                        numLagsDict=parameters['numLagsDict'],\n",
    "                        rowsPerDay=parameters['rowsPerDay'])\n",
    "    testData = getData(testFilename,\n",
    "                        numLagsDict=parameters['numLagsDict'],\n",
    "                        rowsPerDay=parameters['rowsPerDay'])\n",
    "    firstTestTimestamp = testData.loc[0, 'timestamp']\n",
    "\n",
    "    # Concatenate the last trainWindowSize - trainToPredictOffset - 1 rows of the training data with the test data.\n",
    "    # The training window will 'roll' across this training set 'tail', using these rows to estimate the model\n",
    "    # coefficients and make predictions for the first trainWindowSize observations in the test set.\n",
    "    df = pd.concat([trainData.tail(parameters['trainWindowSize'] + parameters['trainToPredictOffset'] - 1), testData])\n",
    "    df.index = np.arange(len(df))\n",
    "\n",
    "    # Intialize the prediction column.\n",
    "    df['prediction'] = 0.\n",
    "    # Intialize ridge regression model with specified alpha (hyperparameter controlling l2 regrularization).\n",
    "    ridgeModel = Ridge(alpha=parameters['alpha'], fit_intercept=False)\n",
    "\n",
    "    # Perform the rolling window regression by incrementally advancing the training window across the concatenated dataframe.\n",
    "    # At each step (while there are predictions to make), estimate the model with the trainWindowSize rows in the training window,\n",
    "    # make forecastHorizon forward predictions and 'roll' the training window forward by forecastHorizon steps.\n",
    "    startTrainIndex = 0\n",
    "    while startTrainIndex + parameters['trainWindowSize'] + parameters['trainToPredictOffset'] <= len(df):\n",
    "        estimateForecastWindow(\n",
    "            df, startTrainIndex, parameters['trainWindowSize'], parameters['forecastHorizon'],\n",
    "            covariates=[var+'DiffLag'+str(lag) for var,numLag in parameters['numLagsDict'].items() for lag in range(numLag)],\n",
    "            ridgeModel=ridgeModel,\n",
    "            trainToPredictOffset=parameters['trainToPredictOffset']\n",
    "        )\n",
    "        startTrainIndex += parameters['forecastHorizon']\n",
    "\n",
    "    df['squaredError'] = np.square(df['prediction'] - df['returns'])\n",
    "    print(sum(df['squaredError'] - np.square(df['returns'])))\n",
    "    print(np.mean(df['squaredError'][df['timestamp'] >= firstTestTimestamp]))\n",
    "    print(np.mean(np.square(df['returns'])[df['timestamp'] >= firstTestTimestamp]))\n",
    "\n",
    "    return df['prediction'][df['timestamp'] >= firstTestTimestamp].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f9a4b9d0-51b1-457f-926d-2f54aa9cafe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.869411700046005\n",
      "0.018128463015986942\n",
      "0.018283162038706575\n",
      "Finished 'modelForecast' in 10.3184 secs\n"
     ]
    }
   ],
   "source": [
    "parameters = modelEstimate(trainingFilename='./train.csv')\n",
    "preds_out = modelForecast(testFilename='./test.csv', parameters=parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsa",
   "language": "python",
   "name": "gsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
